{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Robustness Toolkit (NRTK) demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an end-to-end demostration of Dioptra that can be run on any modern laptop."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import importlib.util\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def register_python_source_file(module_name: str, filepath: Path) -> None:\n",
    "    \"\"\"Import a source file directly.\n",
    "\n",
    "    Args:\n",
    "        module_name: The module name to associate with the imported source file.\n",
    "        filepath: The path to the source file.\n",
    "\n",
    "    Notes:\n",
    "        Adapted from the following implementation in the Python documentation:\n",
    "        https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly\n",
    "    \"\"\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, str(filepath))\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Experiment name\n",
    "EXPERIMENT_NAME = \"pytorch_maite_nrtk\"\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = \"http://localhost:80\"\n",
    "\n",
    "# Set DIOPTRA_RESTAPI_URI variable if not defined, used to connect to RESTful API service\n",
    "os.environ[\"DIOPTRA_RESTAPI_URI\"] = RESTAPI_ADDRESS\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:35000\"\n",
    "\n",
    "# Set MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\") is None:\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Register the examples/scripts directory as a Python module\n",
    "register_python_source_file(\"scripts\", Path(\"..\", \"scripts\", \"__init__.py\"))\n",
    "\n",
    "from scripts.client import DioptraClient\n",
    "from scripts.utils import make_tar\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entrypoints that we will be running in this example are implemented in the Python source files under `src/` and the `src/MLproject` file.\n",
    "To run these entrypoints within Dioptra's architecture, we need to package those files up into an archive and submit it to the Dioptra RESTful API to create a new job.\n",
    "For convenience, we provide the `make_tar` helper function defined in `examples/scripts/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_nrtk):\n",
    "    return response_nrtk[\"mlflowRunId\"] is None and response_nrtk[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/bhodges/Desktop/Dioptra branches/bjpatrick-dioptra-nrtk/examples/pytorch-obj-detect-nrtk/workflows.tar.gz')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_tar([\"src\"], WORKFLOWS_TAR_GZ)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `examples/scripts/client.py` file that is able to connect with the Dioptra RESTful API using the HTTP protocol.\n",
    "We connect using the client below.\n",
    "The client uses the environment variable `DIOPTRA_RESTAPI_URI`, which we configured at the top of the notebook, to figure out how to connect to the Dioptra RESTful API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "restapi_client = DioptraClient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m╭─────────────────────────────────────────────────╮\u001b[0m\n",
      "\u001b[1;36m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mDioptra Examples - Register Custom Task Plugins\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36m│\u001b[0m\n",
      "\u001b[1;36m╰─────────────────────────────────────────────────╯\u001b[0m\n",
      " ‣ \u001b[1mplugins_dir:\u001b[0m ..\u001b[35m/\u001b[0m\u001b[95mtask-plugins\u001b[0m\n",
      " ‣ \u001b[1mapi_url:\u001b[0m \u001b[4;39mhttp://localhost:80\u001b[0m\n",
      " ‣ \u001b[1mforce:\u001b[0m \u001b[3;92mTrue\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'pytorch_mi'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'model_inversion'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'modelscan'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'custom_poisoning_plugins'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'custom_fgm_plugins'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'pixel_threshold'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'custom_patch_plugins'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'maite'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'pytorch_d2'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'evaluation'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'feature_squeezing'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'nrtk'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m Custom task plugin registration is complete.\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/register_task_plugins.py --force --plugins-dir ../task-plugins --api-url http://localhost:80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experimentId': 1,\n",
       " 'createdOn': '2024-07-13T18:27:57.486712',\n",
       " 'lastModified': '2024-07-13T18:27:57.486712',\n",
       " 'name': 'pytorch_maite_nrtk'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `full_workflow` entry point tests basic MAITE functionality: load a dataset from huggingface, load a model from huggingface, load a metric from torchvision and run that metric on that model/dataset. It also saves the model into MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_test_metrics = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"full_workflow\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P dataset_provider_name=torchvision\",\n",
    "        \"-P dataset_name=voc\",\n",
    "        \"-P dataset_task=object-detection\",\n",
    "        \"-P split=val\",\n",
    "        \"-P model_provider_name=torchvision\",\n",
    "        \"-P model_name=fasterrcnn_resnet50_fpn\",\n",
    "        \"-P model_task=object-detection\",\n",
    "        \"-P metric_provider_name=torchmetrics\",\n",
    "        \"-P metric_name=MeanAveragePrecision\",\n",
    "        \"-P metric_task=detection\",\n",
    "        \"-P classes=46\",\n",
    "        \"-P batch_size=4\",\n",
    "        \"-P shape=[800,800]\"\n",
    "    ]),\n",
    "    queue=\"pytorch_cpu\",\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "pprint.pprint(response_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `save_model` entry point loads a model from huggingface and saves it to MLFlow. In this example, we are pulling this object detection model from huggingface: https://huggingface.co/spaces/lkeab/transfiner/tree/main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'createdOn': '2024-07-16T20:41:05.733304',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'save_model',\n",
      " 'entryPointKwargs': '-P model_provider_name=torchvision -P '\n",
      "                     'model_name=fasterrcnn_resnet50_fpn -P '\n",
      "                     'model_task=object-detection',\n",
      " 'experimentId': 1,\n",
      " 'jobId': 'd77bda2f-a610-4bf5-a6c1-4788205eb880',\n",
      " 'lastModified': '2024-07-16T20:41:05.733304',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 3,\n",
      " 'status': 'queued',\n",
      " 'timeout': '1h',\n",
      " 'workflowUri': 's3://workflow/4340a0e2bd5e4901adeccd9de152bc5b/workflows.tar.gz'}\n"
     ]
    }
   ],
   "source": [
    "response_model = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"save_model\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P model_provider_name=torchvision\",\n",
    "        \"-P model_name=fasterrcnn_resnet50_fpn\",\n",
    "        \"-P model_task=object-detection\"\n",
    "    ]),\n",
    "    queue=\"pytorch_cpu\",\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "pprint.pprint(response_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scan_model` entrypoint loads the previously saved model from MLFlow and uses modelscan to evaluate the model files for insecure or malicious code.\n",
    "\n",
    "It is important to note that modelscan searches for publicly known vulnerable coding practices, which the tool labels as a CRITICAL vulnerability. If the tool is used to scan models on opensource platforms like HuggingFace, there is a possibility for the tool to report a critical finding. Use caution when engaging with models that produce critical scan reports and ensure the model is published by a trusted source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'createdOn': '2024-07-16T20:44:08.019447',\n",
      " 'dependsOn': 'd77bda2f-a610-4bf5-a6c1-4788205eb880',\n",
      " 'entryPoint': 'scan_model',\n",
      " 'entryPointKwargs': '-P mlflow_run_id=fe5b0db1fee14cb294e8c1c87acf7720',\n",
      " 'experimentId': 1,\n",
      " 'jobId': 'f4b45e7f-f60e-4004-8a72-a95d119d66db',\n",
      " 'lastModified': '2024-07-16T20:44:08.019447',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 3,\n",
      " 'status': 'queued',\n",
      " 'timeout': '1h',\n",
      " 'workflowUri': 's3://workflow/1d40de8c18b649ddb230a2d88ebf9a99/workflows.tar.gz'}\n"
     ]
    }
   ],
   "source": [
    "while mlflow_run_id_is_not_known(response_model):\n",
    "    time.sleep(1)\n",
    "    response_model = restapi_client.get_job_by_id(response_model[\"jobId\"])\n",
    "\n",
    "response_scan_model = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"scan_model\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        f\"-P mlflow_run_id={response_model['mlflowRunId']}\",\n",
    "    ]),\n",
    "    queue=\"pytorch_cpu\",\n",
    "    timeout=\"1h\",\n",
    "    depends_on=response_model[\"jobId\"],\n",
    ")\n",
    "pprint.pprint(response_scan_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `test_model` entrypoint loads the previously saved model from MLFlow into a MAITE-readable format, and then uses maite to test metrics and a dataset on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "while mlflow_run_id_is_not_known(response_model):\n",
    "    time.sleep(1)\n",
    "    response_model = restapi_client.get_job_by_id(response_model[\"jobId\"])\n",
    "\n",
    "response_use_model = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"test_model\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P model_name=loaded_model\",\n",
    "        \"-P model_version=1\",\n",
    "        \"-P model_task=object-detection\", \n",
    "        \"-P dataset_provider_name=huggingface\",\n",
    "        \"-P dataset_name=detection-datasets/fashionpedia\",\n",
    "        \"-P dataset_task=object-detection\",\n",
    "        \"-P split=val\",\n",
    "        \"-P metric_provider_name=torchmetrics\",\n",
    "        \"-P metric_name=MeanAveragePrecision\", \n",
    "        \"-P metric_task=detection\",\n",
    "        \"-P classes=80\",\n",
    "        \"-P batch_size=4\",\n",
    "        \"-P shape=[800,800]\"\n",
    "    ]),\n",
    "    queue=\"pytorch_cpu\",\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "#HuggingFace datasets:\n",
    "#detection-datasets/fashionpedia; classes=46; TEST STATUS=Success\n",
    "#detection-datasets/coco; classes=80; TEST STATUS=Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_dataset` entrypoint loads a dataset from disk, puts it into maite format, then loads a model and metric using maite and runs it on that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_load_dataset = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"load_dataset\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P subset=400\"\n",
    "    ]),\n",
    "    queue=\"pytorch_cpu\",\n",
    "    timeout=\"1h\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gen_nrtk` entrypoint loads a dataset using MAITE, applies a NRTK perturbations on it, creates a new `perturbed_dataset` and registers it to MLFlow as an artifact. \n",
    "\n",
    "Currently, Dioptra's NRTK custom plugin is configured to apply skimage and PIL perturbations to object detection datasets. For more insight into NRTK's perturbations, please refer to their documentation. Parameters for this example were derived from NRTK's perturbation jupyter notebook example here: https://github.com/Kitware/nrtk/blob/main/examples/perturbers.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_gen_nrtk = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"gen_nrtk\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P dataset_provider_name=huggingface\",\n",
    "        \"-P dataset_name=detection-datasets/fashionpedia\",\n",
    "        \"-P dataset_task=object-detection\",\n",
    "        \"-P split=val\",\n",
    "        \"-P perturbation=SaltNoisePerturber\",\n",
    "        \"-P seed=42\",\n",
    "        \"-P amount=0.25\"\n",
    "    ]),\n",
    "    queue=\"pytorch_cpu\",\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "#Tested datasets\n",
    "#dataset_provider_name=huggingface; dataset_name=detection-datasets/coco\n",
    "#dataset_provider_name=huggingface; dataset_name=detection-datasets/fashionpedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `infer_nrtk` entrypoint takes the previously generated `perturbed_dataset` results and runs it against a given model and metric. It is included here as a function and tested against 4 models on huggingface from different authors. Note that not all targeted models on huggingface are compatible for various reasons - missing `config.json`, different requirements for data formatting, etc. The examples included below worked at the time of testing.\n",
    "\n",
    "Although MAITE supports torchvision as a provider as well, torchvision does not seem to provide pretrained CIFAR10 models. An ImageNET example may be more suited to cross-testing torchvision and huggingface models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nrtk_dataset(provider, model):\n",
    "    global response_gen_nrtk\n",
    "    while mlflow_run_id_is_not_known(response_gen_nrtk):\n",
    "        time.sleep(1)\n",
    "        response_gen_nrtk = restapi_client.get_job_by_id(response_gen_nrtk[\"jobId\"])\n",
    "    response_infer_nrtk = restapi_client.submit_job(\n",
    "        workflows_file=WORKFLOWS_TAR_GZ,\n",
    "        experiment_name=EXPERIMENT_NAME,\n",
    "        entry_point=\"infer_nrtk\",\n",
    "        entry_point_kwargs=\" \".join([\n",
    "            f\"-P run_id={response_gen_nrtk['mlflowRunId']}\",\n",
    "            f\"-P model_provider_name={provider}\",\n",
    "            f\"-P model_name={model}\",\n",
    "            f\"-P model_task=image-classification\"\n",
    "        ]),\n",
    "        queue=\"pytorch_cpu\",\n",
    "        timeout=\"1h\",\n",
    "        depends_on=response_gen_nrtk[\"jobId\"],\n",
    "    )\n",
    "    return response_infer_nrtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jobId': '005bdf2e-ec0f-4947-a3eb-c13d8d4a82ed',\n",
       " 'mlflowRunId': None,\n",
       " 'experimentId': 1,\n",
       " 'queueId': 3,\n",
       " 'createdOn': '2024-07-16T22:13:32.531231',\n",
       " 'lastModified': '2024-07-16T22:13:32.531231',\n",
       " 'timeout': '1h',\n",
       " 'workflowUri': 's3://workflow/cfb8540537e84152a3f8d1189ed92c6c/workflows.tar.gz',\n",
       " 'entryPoint': 'infer_nrtk',\n",
       " 'entryPointKwargs': '-P run_id=171fdfd812a848278e5d35bab2960e72 -P model_provider_name=torchvision -P model_name=fasterrcnn_resnet50_fpn -P model_task=object-detection',\n",
       " 'dependsOn': 'a32b9497-2f92-4112-9f2c-da54ff4d7521',\n",
       " 'status': 'queued'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_perturbed_dataset_nrtk(\"torchvision\",\"fasterrcnn_resnet50_fpn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perturbed_dataset_nrtk(\"huggingface\",\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edee40310913f16e2ca02c1d37887bcb7f07f00399ca119bb7e27de7d632ea99"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
