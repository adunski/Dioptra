{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow MNIST Feature Squeezing Defense demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">⚠️ **Warning:** Some of the attacks in this demo, _deepfool_ and _CW_ in particular, are computationally expensive and will take a very long to complete if run using the CPUs found in a typical personal computer.\n",
    "> For this reason, it is highly recommended that you run these demos on a CUDA-compatible GPU.\n",
    "\n",
    "This notebook contains a demonstration of how to use Dioptra to run experiments that investigate the effectiveness of the feature-squeezing defense against a series of evasion attacks against a neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Address for connecting the docker container to exposed ports on the host device\n",
    "HOST_DOCKER_INTERNAL = \"host.docker.internal\"\n",
    "# HOST_DOCKER_INTERNAL = \"172.17.0.1\"\n",
    "\n",
    "# Dioptra API ports\n",
    "RESTAPI_PORT = \"30080\"\n",
    "MLFLOW_TRACKING_PORT = \"35000\"\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = (\n",
    "    f\"http://{HOST_DOCKER_INTERNAL}:{RESTAPI_PORT}\"\n",
    "    if os.getenv(\"IS_JUPYTER_SERVICE\")\n",
    "    else f\"http://localhost:{RESTAPI_PORT}\"\n",
    ")\n",
    "\n",
    "# Override the DIOPTRA_RESTAPI_URI variable, used to connect to RESTful API service\n",
    "os.environ[\"DIOPTRA_RESTAPI_URI\"] = RESTAPI_ADDRESS\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = (\n",
    "    f\"http://{HOST_DOCKER_INTERNAL}:{MLFLOW_TRACKING_PORT}\"\n",
    "    if os.getenv(\"IS_JUPYTER_SERVICE\")\n",
    "    else f\"http://localhost:{MLFLOW_TRACKING_PORT}\"\n",
    ")\n",
    "\n",
    "# Override the MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Base API address\n",
    "RESTAPI_API_BASE = f\"{RESTAPI_ADDRESS}/api\"\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "import requests\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Import utils.py file\n",
    "import utils\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)\n",
    "\n",
    "# Configure paths to datasets\n",
    "data_path_mnist = \"/nfs/data/Mnist\"\n",
    "data_path_imagenet = \"/nfs/data/ImageNet-Kaggle-2017/images/ILSVRC/Data/CLS-LOC/val-sorted-1000\"\n",
    "\n",
    "# Configure experiment namespaces\n",
    "mlflow_queue = \"tensorflow_gpu\" # Change this queue if needed.\n",
    "uid = \"plugin\".lower() #Replace placeholder with your desired UserID. This can be anything, but will be viewable to other users of the platform.\n",
    "experiment = uid + \"_feature_squeeze\"\n",
    "model_id = \"1\" #change this if you have multiple models with the same name. Defaults to str(1)\n",
    "mnist_model = experiment + \"_le_net\" \n",
    "mnist_shallow = experiment + \"_shallow_net\"\n",
    "mnist_logit = mnist_model + \"_logit\"\n",
    "imagenet_model = experiment + \"_default_pretrained_mobilenet_logits/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained a copy of the MNIST dataset as part of the startup process invoked by `make demo`.\n",
    "The training and testing images for the MNIST dataset are stored within the `data/` directory as PNG files that are organized into the following folder structure,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    data\n",
    "    ├── testing\n",
    "    │   ├── 0\n",
    "    │   ├── 1\n",
    "    │   ├── 2\n",
    "    │   ├── 3\n",
    "    │   ├── 4\n",
    "    │   ├── 5\n",
    "    │   ├── 6\n",
    "    │   ├── 7\n",
    "    │   ├── 8\n",
    "    │   └── 9\n",
    "    └── training\n",
    "        ├── 0\n",
    "        ├── 1\n",
    "        ├── 2\n",
    "        ├── 3\n",
    "        ├── 4\n",
    "        ├── 5\n",
    "        ├── 6\n",
    "        ├── 7\n",
    "        ├── 8\n",
    "        └── 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subfolders under `data/training/` and `data/testing/` are the classification labels for the images in the dataset.\n",
    "This folder structure is a standardized way to encode the label information and many libraries can make use of it, including the Tensorflow library that we are using for this particular demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entrypoints that we will be running in this example are implemented in the Python source files under `src/` and the `MLproject` file.\n",
    "To run these entrypoints within Dioptra's architecture, we need to package those files up into an archive and submit it to the Dioptra RESTful API to create a new job.\n",
    "For convenience, the `Makefile` provides a rule for creating the archive file for this example, just run `make workflows`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create the workflows.tar.gz file\n",
    "make workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `utils.py` file that is able to connect with the Dioptra RESTful API using the HTTP protocol.\n",
    "We connect using the client below, which uses the environment variable `DIOPTRA_RESTAPI_URI` to figure out how to connect to the Dioptra RESTful API,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restapi_client = utils.DioptraClient(address=RESTAPI_API_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=experiment)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=experiment)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also check which queues are available for running our jobs to make sure that the resources that we need are available.\n",
    "The code below queries the Lab API and returns a list of active queues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### restapi_client.list_queues()  #Deprecated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this section is divided into two parts.\n",
    "Both parts investigate the effectiveness of the feature squeezing defense against several kinds of evasion attacks, but differ in the dataset and model architectures used.\n",
    "The first part uses the MNIST dataset and LeNet-5 architecture, while the second part uses the ImageNet dataset and the mobilenet CNN architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be training the LeNet-5 model from scratch on the MNIST dataset,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit training job for the LeNet-5 network architecture\n",
    "response_le_net_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        f\"-P register_model_name={mnist_model}\",\n",
    "        \"-P model_architecture=le_net\",\n",
    "        \"-P epochs=30\",\n",
    "        \"-P data_dir=/nfs/data/Mnist\"\n",
    "    ]),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Training job for LeNet-5 neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_le_net_train)\n",
    "#        \"-P data_dir=/nfs/data/Mnist\"\n",
    "#  \"-P register_model=True\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit training job for the shallownet network architecture\n",
    "response_le_net_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        f\"-P register_model_name={mnist_shallow}\",\n",
    "        \"-P model_architecture=shallow_net\",\n",
    "        \"-P epochs=30\",\n",
    "        \"-P data_dir=/nfs/data/Mnist\"\n",
    "    ]),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Training job for LeNet-5 neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_le_net_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block generates adversarial images on the MNIST dataset using the Fast Gradient Method attack and then attempts to classify the adversarial images.\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `eps` | _float_ | Attack step size. \\[default: 0.3\\] |\n",
    "| `eps_step` | _float_ | Step size of input variation for minimal perturbation computation. [default: 0.1] |\n",
    "| `targeted` | _bool_ | Indicates whether the attack is targeted (True) or untargeted (False). [default: False] |\n",
    "| `num_random_init` | _int_ | Number of random initializations within the epsilon ball. For ``random_init=0`` starting at the original input. [default: 0] |\n",
    "| `minimal` | _bool_ | Indicates if computing the minimal perturbation (True). If True, also define eps_step for the step size and eps for the maximum perturbation. [default: False] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"fgm\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [f\"-P model_name={mnist_model}\",\"-P data_dir=/nfs/data/Mnist\",f\"-P model_version={model_id}\"]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    timeout=\"1m\"\n",
    "\n",
    ")\n",
    "\n",
    "print(\"FGM attack job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"]) \n",
    "    \n",
    "response_infer = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_fgm_le_net[\"jobId\"]\n",
    ")\n",
    "    \n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps.\n",
    "This pre-processing defense compresses the images being classified by our neural network such that their color depth is reduced to a binary, monochrome pallete.\n",
    "The level of compression can be tuned by adjusting the bit_depth parameter below (use values between 1 (binary) and 8 (original image color depth) to tune the defense.\n",
    "\n",
    "**FGM parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `eps` | _float_ | Attack step size. \\[default: 0.3\\] |\n",
    "| `eps_step` | _float_ | Step size of input variation for minimal perturbation computation. [default: 0.1] |\n",
    "| `targeted` | _bool_ | Indicates whether the attack is targeted (True) or untargeted (False). [default: False] |\n",
    "| `num_random_init` | _int_ | Number of random initializations within the epsilon ball. For ``random_init=0`` starting at the original input. [default: 0] |\n",
    "| `minimal` | _bool_ | Indicates if computing the minimal perturbation (True). If True, also define eps_step for the step size and eps for the maximum perturbation. [default: False] |\n",
    "\n",
    "**Feature squeezing parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `bit_depth` | _int_ | An integer between 1-8 that defines the color depth of the squeezed image. [default: 8] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name= experiment,\n",
    "    entry_point=\"fgm\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [f\"-P model_name={mnist_model}\",\"-P data_dir=/nfs/data/Mnist\",f\"-P model_version={model_id}\"]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print(\"FGM attack  job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_model}\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    "    timeout = \"1h\"\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_feature_squeeze[\"jobId\"]) \n",
    "    \n",
    "response_infer_defended = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_feature_squeeze[\"jobId\"]\n",
    ")\n",
    "    \n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the carlini-wagner attack with the Linf distance metric to generate adversarial images and checks the model's accuracy against the attack.\n",
    "\n",
    "**Carlini Wagner Parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `targeted` | _bool_ | Indicates whether the attack is targeted (True) or untargeted (False). [default: False] |\n",
    "| `learning_rate` | _float_ | The initial learning rate for the attack algorithm. Smaller values produce better results but are slower to converge. [default: 0.01] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"cw_inf\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [f\"-P model_name={mnist_shallow}\", f\"-P model_version={model_id}\", \"-P model_architecture=shallow_net\",\"-P targeted=True\", \"-P max_iter=10\",\"-P confidence=0.0\", \"-P max_doubling=10\",\"-P data_dir=/nfs/data/Mnist\",  \"-P learning_rate=0.01\", \"-P max_halving=10\", \"-P verbose=True\", \"-P batch_size=32\"]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "#model_architecture=le_net\n",
    "print(\"Carlini Wagner attack job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "         [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps.\n",
    "This defense may be tuned and adjusted in the same manner as the previous feature squeeze block defending against the FGM attack.\n",
    "\n",
    "**Carlini Wagner Parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `targeted` | _bool_ | Indicates whether the attack is targeted (True) or untargeted (False). [default: False] |\n",
    "| `learning_rate` | _float_ | The initial learning rate for the attack algorithm. Smaller values produce better results but are slower to converge. [default: 0.01] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"cw_inf\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [f\"-P model_name={mnist_shallow}\", \n",
    "         f\"-P model_version={model_id}\", \n",
    "         \"-P model_architecture=shallow_net\",\n",
    "         \"-P targeted=True\", \n",
    "         \"-P max_iter=20\",\n",
    "         \"-P confidence=0.0\", \n",
    "         \"-P max_doubling=10\",\n",
    "         \"-P data_dir=/nfs/data/Mnist\", \n",
    "         \"-P learning_rate=0.01\", \n",
    "         \"-P max_halving=10\", \n",
    "         \"-P verbose=True\", \n",
    "         \"-P batch_size=32\"]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Carlini Wagner attack job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "            f\"-P model_version={model_id}\"\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "            f\"-P model_version={model_id}\"\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the carlini-wagner attack using the L2 distance metric to generate adversarial images and checks the model's accuracy against the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"cw_l2\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [f\"-P model_name={mnist_shallow}\",f\"-P model_version={model_id}\", \"-P binary_search_steps=50\", \"-P initial_const=0.01\", \"-P model_architecture=shallow_net\", \"-P max_iter=10\", \"-P max_doubling=5\",\"-P data_dir=/nfs/data/Mnist\", \"-P max_halving=5\", \"-P verbose=True\", \"-P batch_size=32\"]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Carlini Wagner attack job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"cw\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model={mnist_model}\",\n",
    "            \"-P binary_search_steps=50\",\n",
    "            \"-P initial_const=0.01\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P max_doubling=5\",\n",
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"cw_l2\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [f\"-P model_name={mnist_shallow}\",f\"-P model_version={model_id}\",\"-P binary_search_steps=50\", \"-P initial_const=0.01\", \"-P model_architecture=shallow_net\", \"-P max_iter=10\", \"-P max_doubling=5\",\"-P data_dir=/nfs/data/Mnist\", \"-P max_halving=5\", \"-P verbose=True\", \"-P batch_size=32\"]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Carlini Wagner attack  job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "            f\"-P model_version{model_id}\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_feature_squeeze[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=expperiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\"\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")\n",
    "            f\"-P data_dir={data_path_mnist}\",\n",
    "            \"-P max_halving=5\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P batch_size=32\",\n",
    "        ],\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Carlini Wagner attack (LeNet-5 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_shallow}\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ],\n",
    "    ),\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_feature_squeeze[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=expperiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_shallow}\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P batch_size=32\"\n",
    "        ],\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the Deepfool attack to generate adversarial MNIST images, applies the feature squeezing defense, and checks the model's accuracy against the defended adversarial dataset.\n",
    "\n",
    "**Unique Deepfool parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `epsilon` | _float_ | Overshoot parameter. [default: 0.00001] |\n",
    "| `nb_grads` | _int_ | Number of class gradients to compute. [default: 10] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"deepfool\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model={mnist_model}\",\n",
    "            f\"-P data_dir={data_path_mnist}/training\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P batch_size=32\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P nb_grads=10\",\n",
    "            \"-P epsilon=0.000001\",\n",
    "        ],\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Deepfool attack (Mobilenet architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_model}\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\",\n",
    "            f\"-P data_dir={data_path_mnist}/training\",\n",
    "        ],\n",
    "    ),\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_feature_squeeze[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_model}\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P batch_size=32\"\n",
    "        ],\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the Deepfool attack to generate adversarial MNIST images and checks the model's accuracy against the attack.\n",
    "\n",
    "**Unique Deepfool parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `epsilon` | _float_ | Overshoot parameter. [default: 0.00001] |\n",
    "| `nb_grads` | _int_ | Number of class gradients to compute. [default: 10] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"deepfool\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model={mnist_model}\",\n",
    "            f\"-P data_dir={data_path_mnist}/training\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P batch_size=32\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P nb_grads=10\",\n",
    "            \"-P epsilon=0.000001\",\n",
    "        ],\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Deepfool attack (Mobilenet architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=example,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_model}\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block applies the Jacobian Saliency Map Approach attack to generate adversarial images for the MNIST dataset.\n",
    "\n",
    "**Unique JSMA parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `theta` | _float_ | Amount of Perturbation introduced to each modified feature per step (can be positive or negative). [default: 0.1] |\n",
    "| `gamma` | _float_ | Maximum fraction of features being perturbed (between 0 and 1). [default: 1.0] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_jsma = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"jsma\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [f\"-P model_name={mnist_model}\",\n",
    "         f\"-P model_version={model_id}\", \n",
    "         \"-P model_architecture=le_net\", \n",
    "         \"-P theta=4.5\",\n",
    "         \"-P verbose=True\",\n",
    "         \"-P gamma=1.0\", \n",
    "         \"-P data_dir=/nfs/data/Mnist\"] \n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print(\"JSMA attack (LeNet-5 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_jsma)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_jsma):\n",
    "    time.sleep(1)\n",
    "    response_jsma = restapi_client.get_job_by_id(response_jsma[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_jsma['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_jsma[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_jsma = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"jsma\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [f\"-P model_name={mnist_model}\",\n",
    "         f\"-P model_version={model_id}\", \n",
    "         \"-P model_architecture=le_net\", \n",
    "         \"-P theta=4.5\",\n",
    "         \"-P verbose=True\",\n",
    "         \"-P gamma=1.0\", \n",
    "         \"-P data_dir=/nfs/data/Mnist\"] \n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"JSMA attack (LeNet-5 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_jsma)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_jsma):\n",
    "    time.sleep(1)\n",
    "    response_jsma = restapi_client.get_job_by_id(response_jsma[\"jobId\"])\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "           [\n",
    "            f\"-P run_id={response_jsma['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\"\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_jsma[\"jobId\"],\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_feature_squeeze[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_jsma = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_jsma['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageNet data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block loads a pretrained mobilenet model from `tensorflow.applications`.\n",
    "This is required for sections of the demo classifying images from the Imagenet dataset, specifically those involving the Deepfool attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Submit training job for the LeNet-5 network architecture\n",
    "response_le_net_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"init_model\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P model_architecture=mobilenet\",   \n",
    "        \"-P data_dir=/nfs/data/ImageNet-Kaggle-2017/images/ILSVRC/Data/CLS-LOC/val-sorted-10000\",\n",
    "        \"-P seed=-1\",\n",
    "        \"-P batch_size=40\"\n",
    "    ]),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "# mobilenet\",\n",
    "print(\"Training job for mobilenet neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_le_net_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the Deepfool attack to generate adversarial images and checks the model's accuracy against the attack.\n",
    "Please note that this attack uses the mobilenet CNN architecture and generates adversarial images of the ImageNet dataset.\n",
    "This attack may take quite some time to complete.\n",
    "Due to the long compute times, you may want to run this attack in stages.\n",
    "In a lower cell, we've provided a method for loading an adversarial dataset and running the later steps of the pipeline via runid.\n",
    "\n",
    "**Unique Deepfool parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `epsilon` | _float_ | Overshoot parameter. [default: 0.00001] |\n",
    "| `nb_grads` | _int_ | Number of class gradients to compute. [default: 10] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_df): #Redundant function, but lets us skip FGM cells if desired\n",
    "    return response_df[\"mlflowRunId\"] is None and response_df[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_df_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"deepfool\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model={imagenet_model}\",\n",
    "            f\"-P data_dir={data_path_imagenet}\",\n",
    "            \"-P model_architecture=mobilenet\",\n",
    "            \"-P batch_size=40\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P nb_grads=10\",\n",
    "            \"-P epsilon=0.000001\",\n",
    "        ],\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"DeepFool attack (Mobilenet architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_df_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_df_le_net):\n",
    "    time.sleep(1)\n",
    "    response_df_le_net = restapi_client.get_job_by_id(response_df_le_net[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_df = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_df_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={imagenet_model}\",\n",
    "            \"-P model_architecture=mobilenet\",\n",
    "            \"-P batch_size=40\"\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_df_le_net[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the initial Deepfool block, but adds in a step where the feature squeezing defense is applied before the infer step.\n",
    "As in previous defended code blocks, this may be tuned by adjusting the bit-depth parameter.\n",
    "Note that imagenet uses RGB images, and feature squeezing is applied equally on all channels (meaning that `bit_depth=4` corresponds to R = 4, B = 4, G = 4). \n",
    "\n",
    "**Unique Deepfool parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `epsilon` | _float_ | Overshoot parameter. [default: 0.00001] |\n",
    "| `nb_grads` | _int_ | Number of class gradients to compute. [default: 10] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_df_mobilenet = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"deepfool\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model={imagenet_model}\",\n",
    "            f\"-P data_dir={data_path_imagenet}\",\n",
    "            \"-P model_architecture=mobilenet\",\n",
    "            \"-P batch_size=40\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P nb_grads=10\",\n",
    "            \"-P epsilon=1\",\n",
    "        ],\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Deepfool attack (Mobilenet architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_df_mobilenet)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_df_mobilenet):\n",
    "    time.sleep(1)\n",
    "    response_df_mobilenet = restapi_client.get_job_by_id(response_df_mobilenet[\"jobId\"])\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_df_mobilenet['mlflowRunId']}\",\n",
    "            f\"-P model={imagenet_model}\",\n",
    "            \"-P model_architecture=mobilenet\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=40\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_df_mobilenet[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_feature_squeeze[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_df = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model={imagenet_model}\",\n",
    "            \"-P model_architecture=mobilenet\",\n",
    "            \"-P batch_size=40\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block can be used to manually run both the squeeze and infer steps on a previous deepfool run. \n",
    "Use this to avoid the adversarial image generation step, which may be time consuming.\n",
    "To run this block, you must specify a valid `run_id` and `model`.\n",
    "To manually fetch a run ID, you can navigate to MLFlow Dashboard and select a successful deepfool run.\n",
    "The run ID will be listed on the page header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "\n",
    "runid = \"5cb28628c51b4541bcb68276525f7f1d\"\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={runid}\",\n",
    "            f\"-P model={imagenet_model}\",\n",
    "            \"-P model_architecture=mobilenet\",\n",
    "            \"-P bit_depth=4\",\n",
    "            \"-P batch_size=40\",\n",
    "        ],\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_feature_squeeze[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_df = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=experiment,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model={imagenet_model}\",\n",
    "            \"-P model_architecture=mobilenet\",\n",
    "            \"-P batch_size=40\",\n",
    "        ],\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edee40310913f16e2ca02c1d37887bcb7f07f00399ca119bb7e27de7d632ea99"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('dioptra': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
