{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAITE Compatibility demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an end-to-end demostration of Dioptra that can be run on any modern laptop."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import importlib.util\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def register_python_source_file(module_name: str, filepath: Path) -> None:\n",
    "    \"\"\"Import a source file directly.\n",
    "\n",
    "    Args:\n",
    "        module_name: The module name to associate with the imported source file.\n",
    "        filepath: The path to the source file.\n",
    "\n",
    "    Notes:\n",
    "        Adapted from the following implementation in the Python documentation:\n",
    "        https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly\n",
    "    \"\"\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, str(filepath))\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Experiment name\n",
    "EXPERIMENT_NAME = \"pytorch_maite\"\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = \"http://localhost:30080\"\n",
    "\n",
    "# Set DIOPTRA_RESTAPI_URI variable if not defined, used to connect to RESTful API service\n",
    "os.environ[\"DIOPTRA_RESTAPI_URI\"] = RESTAPI_ADDRESS\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:35000\"\n",
    "\n",
    "# Set MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\") is None:\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Register the examples/scripts directory as a Python module\n",
    "register_python_source_file(\"scripts\", Path(\"..\", \"scripts\", \"__init__.py\"))\n",
    "\n",
    "from scripts.client import DioptraClient\n",
    "from scripts.utils import make_tar\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entrypoints that we will be running in this example are implemented in the Python source files under `src/` and the `src/MLproject` file.\n",
    "To run these entrypoints within Dioptra's architecture, we need to package those files up into an archive and submit it to the Dioptra RESTful API to create a new job.\n",
    "For convenience, we provide the `make_tar` helper function defined in `examples/scripts/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/c/Users/jtsexton/Documents/GitHub/dioptra/examples/pytorch-maite/workflows.tar.gz')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_tar([\"src\"], WORKFLOWS_TAR_GZ)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `examples/scripts/client.py` file that is able to connect with the Dioptra RESTful API using the HTTP protocol.\n",
    "We connect using the client below.\n",
    "The client uses the environment variable `DIOPTRA_RESTAPI_URI`, which we configured at the top of the notebook, to figure out how to connect to the Dioptra RESTful API.\n",
    "\n",
    "The MlflowClient object is used to retrieve our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "restapi_client = DioptraClient()\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m╭─────────────────────────────────────────────────╮\u001b[0m\n",
      "\u001b[1;36m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mDioptra Examples - Register Custom Task Plugins\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36m│\u001b[0m\n",
      "\u001b[1;36m╰─────────────────────────────────────────────────╯\u001b[0m\n",
      " ‣ \u001b[1mplugins_dir:\u001b[0m ..\u001b[35m/\u001b[0m\u001b[95mtask-plugins\u001b[0m\n",
      " ‣ \u001b[1mapi_url:\u001b[0m \u001b[4;39mhttp://localhost:30080\u001b[0m\n",
      " ‣ \u001b[1mforce:\u001b[0m \u001b[3;92mTrue\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'custom_fgm_plugins'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'custom_patch_plugins'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'custom_poisoning_plugins'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'evaluation'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'feature_squeezing'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'maite'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'model_inversion'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\n",
      "\u001b[39m'pixel_threshold'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'pytorch_d2'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'pytorch_fgm'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;33mOverwritten.\u001b[0m \u001b[39mRemoved and re-registered the custom task plugin \u001b[0m\u001b[39m'pytorch_mi'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m Custom task plugin registration is complete.\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/register_task_plugins.py --force --plugins-dir ../task-plugins --api-url http://localhost:30080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m╭────────────────────────────────────╮\u001b[0m\n",
      "\u001b[1;36m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mDioptra Examples - Register Queues\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36m│\u001b[0m\n",
      "\u001b[1;36m╰────────────────────────────────────╯\u001b[0m\n",
      " ‣ \u001b[1mqueue:\u001b[0m \u001b[39mtensorflow_cpu, tensorflow_gpu, pytorch_cpu, pytorch_gpu\u001b[0m\n",
      " ‣ \u001b[1mapi_url:\u001b[0m \u001b[4;39mhttp://localhost:30080\u001b[0m\n",
      "\u001b[1;33mⒾ\u001b[0m  \u001b[1;37mSkipped.\u001b[0m \u001b[39mThe queue \u001b[0m\u001b[39m'tensorflow_cpu'\u001b[0m\u001b[39m is already registered.\u001b[0m\n",
      "\u001b[1;33mⒾ\u001b[0m  \u001b[1;37mSkipped.\u001b[0m \u001b[39mThe queue \u001b[0m\u001b[39m'tensorflow_gpu'\u001b[0m\u001b[39m is already registered.\u001b[0m\n",
      "\u001b[1;33mⒾ\u001b[0m  \u001b[1;37mSkipped.\u001b[0m \u001b[39mThe queue \u001b[0m\u001b[39m'pytorch_cpu'\u001b[0m\u001b[39m is already registered.\u001b[0m\n",
      "\u001b[1;33mⒾ\u001b[0m  \u001b[1;37mSkipped.\u001b[0m \u001b[39mThe queue \u001b[0m\u001b[39m'pytorch_gpu'\u001b[0m\u001b[39m is already registered.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m Queue registration is complete.\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/register_queues.py --api-url http://localhost:30080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experimentId': 1,\n",
       " 'createdOn': '2024-04-11T15:20:35.000038',\n",
       " 'lastModified': '2024-04-11T15:20:35.000038',\n",
       " 'name': 'pytorch_maite'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, shlex\n",
    "\n",
    "def get_output(res):\n",
    "    while mlflow_run_id_is_not_known(res) or res['status'] != \"finished\":\n",
    "        time.sleep(1)\n",
    "        res = restapi_client.get_job_by_id(res[\"jobId\"])\n",
    "    out = mlflow_client.get_run(res[\"mlflowRunId\"])\n",
    "    pprint.pprint(out.data.metrics)\n",
    "def format_kwargs_dict(kwargs_dict):\n",
    "    jsd = json.dumps(kwargs_dict, separators=(',',':'))\n",
    "    return jsd\n",
    "def post_process_kwargs(args):\n",
    "    print(args)\n",
    "    cmdline = \" \".join(\n",
    "        \"-P \" + shlex.quote(arg) for arg in args\n",
    "    )\n",
    "    return cmdline\n",
    "def gen_attack_kwargs(library, name, kwargs_dict):\n",
    "    args = [\n",
    "        \"subset=100\",\n",
    "        \"save_original=False\",\n",
    "        \"batch_size=2\",\n",
    "        f\"attack_name={name}\",\n",
    "        f\"attack_library={library}\",\n",
    "        f\"attack_kwargs={format_kwargs_dict(kwargs_dict)}\"\n",
    "    ]\n",
    "    return post_process_kwargs(args)\n",
    "\n",
    "def submit_job(ep, ep_kwargs):\n",
    "    return restapi_client.submit_job(\n",
    "        workflows_file=WORKFLOWS_TAR_GZ,\n",
    "        experiment_name=EXPERIMENT_NAME,\n",
    "        entry_point=ep,\n",
    "        entry_point_kwargs=ep_kwargs,\n",
    "        queue=\"pytorch_cpu\",\n",
    "        timeout=\"1h\",\n",
    "    )\n",
    "\n",
    "def infer_from_artifact():\n",
    "    return submit_job(ep=\"infer_from_artifact\", ep_kwargs={\"run_id\": \"\",\n",
    "                                                           \"adv_tar_name\": \"fgm.tar.gz\",\n",
    "                                                           \"adv_data_dir\": \"adv_testing\",\n",
    "                                                           \"image_size\": [3,224,224],\n",
    "                                                           \"new_size\": 224})\n",
    "\n",
    "def infer_from_dataset_maite():\n",
    "    kwargs = {'provider_name':'huggingface',\n",
    "               'dataset_name':'cifar10',\n",
    "               'task':'image-classification',\n",
    "               'split':'test'}\n",
    "    ep_kwargs={\"local_dataset\": False, \"dataset_kwargs\": format_kwargs_dict(kwargs) }\n",
    "    \n",
    "    args = post_process_kwargs([m + '=' + str(ep_kwargs[m]) for m in ep_kwargs])\n",
    "    return submit_job(ep=\"infer_from_dataset\",ep_kwargs=args)\n",
    "    \n",
    "def infer_from_dataset_local():\n",
    "    kwargs = {\"data_dir\":\"/dioptra/data/Mnist/testing\",\n",
    "              \"image_size\":\"[28,28,3]\",\n",
    "              \"new_size\":224,\n",
    "              \"validation_split\": 0.3}\n",
    "    ep_kwargs={\"local_dataset\": True, \"dataset_kwargs\": format_kwargs_dict(kwargs) }    \n",
    "    args = post_process_kwargs([m + '=' + str(ep_kwargs[m]) for m in ep_kwargs])\n",
    "\n",
    "    return submit_job(ep=\"infer_from_dataset\", ep_kwargs=args)\n",
    "\n",
    "def register_model_from_maite():\n",
    "    return submit_job(ep=\"register_model\", ep_kwargs={})\n",
    "\n",
    "def gen_attack():\n",
    "    cmdline = gen_attack_kwargs(attack_library, attack_name, kwargs_dict)\n",
    "    return submit_job(ep=\"attack\", ep_kwargs=cmdline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `infer_from_dataset` entry point uses basic MAITE functionality: load a dataset from huggingface or a local dataset, load a model from huggingface or use a registered model, load a metric from torchvision and run that metric on that model/dataset. It also saves the model into MLFlow, if it is a newly loaded model. In this example, we will load both the dataset and the model from MAITE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['local_dataset=False', 'dataset_kwargs={\"provider_name\":\"huggingface\",\"dataset_name\":\"cifar10\",\"task\":\"image-classification\",\"split\":\"test\"}']\n",
      "{'createdOn': '2024-06-18T19:29:52.045294',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'infer_from_dataset',\n",
      " 'entryPointKwargs': '-P local_dataset=False -P '\n",
      "                     '\\'dataset_kwargs={\"provider_name\":\"huggingface\",\"dataset_name\":\"cifar10\",\"task\":\"image-classification\",\"split\":\"test\"}\\'',\n",
      " 'experimentId': 1,\n",
      " 'jobId': '3febbd7e-1304-4c60-a0ab-ca8a5d7457e0',\n",
      " 'lastModified': '2024-06-18T19:29:52.045294',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 3,\n",
      " 'status': 'queued',\n",
      " 'timeout': '1h',\n",
      " 'workflowUri': 's3://workflow/938ee15e18c44663878ba27e0b564661/workflows.tar.gz'}\n"
     ]
    }
   ],
   "source": [
    "response_test_metrics = infer_from_dataset_maite()  # pull a dataset from maite, and a model from maite.\n",
    "pprint.pprint(response_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will load the dataset from disk and the model from MAITE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['local_dataset=True', 'dataset_kwargs={\"data_dir\":\"/dioptra/data/Mnist/testing\",\"image_size\":\"[28,28,3]\",\"new_size\":224,\"validation_split\":0.3}']\n",
      "{'createdOn': '2024-06-18T19:33:15.474895',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'infer_from_dataset',\n",
      " 'entryPointKwargs': '-P local_dataset=True -P '\n",
      "                     '\\'dataset_kwargs={\"data_dir\":\"/dioptra/data/Mnist/testing\",\"image_size\":\"[28,28,3]\",\"new_size\":224,\"validation_split\":0.3}\\'',\n",
      " 'experimentId': 1,\n",
      " 'jobId': '6e07c700-0869-44f7-bc2f-545a15b7c7de',\n",
      " 'lastModified': '2024-06-18T19:33:15.474895',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 3,\n",
      " 'status': 'queued',\n",
      " 'timeout': '1h',\n",
      " 'workflowUri': 's3://workflow/1ef5b336c8cf4efd9c02d452a7ca12d3/workflows.tar.gz'}\n"
     ]
    }
   ],
   "source": [
    "response_test_metrics = infer_from_dataset_local()  # load a dataset from disk, and a model from maite.\n",
    "pprint.pprint(response_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `register_model` entry point loads a model from huggingface and saves it to MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_model_from_maite()\n",
    "pprint.pprint(response_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `test_model` entrypoint loads the previously saved model from MLFlow into a MAITE-readable format, and then uses maite to test metrics and a dataset on it.\n",
    "\n",
    "Note: Currently this saves the dataset to /dioptra/data/tmp - make sure the docker container has permissions to write to this area or change the location this is saved to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while mlflow_run_id_is_not_known(response_model):\n",
    "    time.sleep(1)\n",
    "    response_model = restapi_client.get_job_by_id(response_model[\"jobId\"])\n",
    "\n",
    "response_use_model = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"test_model\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P model_name=loaded_model\",\n",
    "        \"-P model_version=1\",\n",
    "        \"-P subset=500\"\n",
    "    ]),\n",
    "    queue=\"pytorch_cpu\",\n",
    "    timeout=\"1h\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gen` entrypoint loads a dataset using MAITE, runs the specified attack on it, saves the output of the attack to MLFlow as an artifact, and has the option to write the original dataset to disk (configurable). The `do_gen_attack` function takes the class name of the attack, as well as a dictionary of parameters. Any unnecessary parameters will be filtered out and reported in the logs.\n",
    "\n",
    "Note: While this function in theory could work with poisoning attacks since it uses heart-lib, and does not have anything specifically requiring an evasion attack, at the time of writing there did not seem to exist a compatible poisoning example. This is largely due to poisoning examples requiring either knowledge of the feature layers from the model (and this information is not available in the context of this notebook) or in the case of PoisoningAttackBackdoor, due to an incompatibility with heartlib. It is possible that in the future this may be corrected and that example may work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_gen_fgm = do_gen_attack(\"FastGradientMethod\", {'eps': 0.3, 'eps_step': 0.1, 'norm': 'inf', 'minimal': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may require GPU\n",
    "response_gen_pt = do_gen_attack(\"PixelAttack\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may require GPU\n",
    "response_gen_pgd = do_gen_attack(\"ProjectedGradientDescentPyTorch\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may require GPU\n",
    "response_gen_hsj = do_gen_attack(\"HopSkipJump\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# does not work currently due to problem with heartlib, but includes syntax for passing an existing function as an argument, and also for using a different library\n",
    "# response_gen_poison = do_gen_attack(\"PoisoningAttackBackdoor\", {'perturbation_FUNCTION': 'art.attacks.poisoning.perturbations.add_single_bd' }, attack_library='art.attacks.poisoning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `infer` entrypoint takes the previously generated fgm attack results and runs it against a given model and metric. It is included here as a function and tested against 4 models on huggingface from different authors. Note that not all CIFAR10 targeted models on huggingface are compatible for various reasons - missing `config.json`, different requirements for data formatting, etc. The examples included below worked at the time of testing.\n",
    "\n",
    "Although MAITE supports torchvision as a provider as well, torchvision does not seem to provide pretrained CIFAR10 models. An ImageNET example may be more suited to cross-testing torchvision and huggingface models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cifar10_fgm(provider, model):\n",
    "    global response_gen_fgm\n",
    "    while mlflow_run_id_is_not_known(response_gen_fgm):\n",
    "        time.sleep(1)\n",
    "        response_gen_fgm = restapi_client.get_job_by_id(response_gen_fgm[\"jobId\"])\n",
    "    response_infer_fgm = restapi_client.submit_job(\n",
    "        workflows_file=WORKFLOWS_TAR_GZ,\n",
    "        experiment_name=EXPERIMENT_NAME,\n",
    "        entry_point=\"infer\",\n",
    "        entry_point_kwargs=\" \".join([\n",
    "            f\"-P run_id={response_gen_fgm['mlflowRunId']}\",\n",
    "            f\"-P model_provider_name={provider}\",\n",
    "            f\"-P model_name={model}\",\n",
    "            f\"-P model_task=image-classification\"\n",
    "        ]),\n",
    "        queue=\"pytorch_cpu\",\n",
    "        timeout=\"1h\",\n",
    "        depends_on=response_gen_fgm[\"jobId\"],\n",
    "    )\n",
    "    return response_infer_fgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_results = test_cifar10_fgm(\"huggingface\",\"aaraki/vit-base-patch16-224-in21k-finetuned-cifar10\")\n",
    "get_output(model1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_results = test_cifar10_fgm(\"huggingface\",\"abhishek/autotrain_cifar10_vit_base\")\n",
    "get_output(model2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_results = test_cifar10_fgm(\"huggingface\",\"Weili/vit-base-patch16-224-finetuned-cifar10\")\n",
    "get_output(model3_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4_results = test_cifar10_fgm(\"huggingface\",\"arize-ai/resnet-50-cifar10-quality-drift\")\n",
    "get_output(model4_results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edee40310913f16e2ca02c1d37887bcb7f07f00399ca119bb7e27de7d632ea99"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
