# This Software (Dioptra) is being made available as a public service by the
# National Institute of Standards and Technology (NIST), an Agency of the United
# States Department of Commerce. This software was developed in part by employees of
# NIST and in part by NIST contractors. Copyright in portions of this software that
# were developed by NIST contractors has been licensed or assigned to NIST. Pursuant
# to Title 17 United States Code Section 105, works of NIST employees are not
# subject to copyright protection in the United States. However, NIST may hold
# international copyright in software created by its employees and domestic
# copyright (or licensing rights) in portions of software that were assigned or
# licensed to NIST. To the extent that NIST holds copyright in this software, it is
# being made available under the Creative Commons Attribution 4.0 International
# license (CC BY 4.0). The disclaimers of the CC BY 4.0 license apply to all parts
# of the software developed or licensed by NIST.
#
# ACCESS THE FULL CC BY 4.0 LICENSE HERE:
# https://creativecommons.org/licenses/by/4.0/legalcode
name: imagenet-resnet50-fgm

entry_points:
  gen_patch:
    parameters:
      data_dir: {type: path, default: "/dioptra/data/Mnist/training" }
      model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      model_version: { type: string, default: "1" }
      image_size: { type: string, default: "28,28,1" }
      adv_tar_name: { type: string, default: "adversarial_patch.tar.gz" }
      adv_data_dir: { type: string, default: "adv_patches" }
      rotation_max: {type: float, default: 22.5}
      scale_min: {type: float, default: 0.1}
      scale_max: {type: float, default: 1.0}
      learning_rate: {type: float, default: 5.0}
      max_iter: {type: int, default: 500}
      patch_target: {type: int, default: -1}
      num_patch: {type: int, default: 1}
      num_patch_gen_samples: {type: int, default: 10}
      imagenet_preprocessing: { type: string, default: "false"}
      seed: {type: float, default: -1}
    command: >
      python generate_patch.py
      --data-dir {data_dir}
      --rotation-max {rotation_max}
      --scale-max {scale_max}
      --scale-min {scale_min}
      --learning-rate {learning_rate}
      --max-iter {max_iter}
      --patch-target {patch_target}
      --num-patch {num_patch}
      --num-patch-gen-samples {num_patch_gen_samples}
      --image-size {image_size}
      --adv-tar-name {adv_tar_name}
      --adv-data-dir {adv_data_dir}
      --model-name {model_name}
      --model-version {model_version}
      --imagenet-preprocessing {imagenet_preprocessing}
      --seed {seed}

  deploy_patch:
    parameters:
      data_dir: {type: path, default: "/dioptra/data/Mnist/testing" }
      run_id: {type: string}
      model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      model_version: { type: string, default: "1" }
      image_size: { type: string, default: "28,28,1" }
      adv_tar_name: { type: string, default: "adversarial_patch_dataset.tar.gz" }
      adv_data_dir: { type: string, default: "adv_patch_dataset" }
      adv_patch_tar_name: { type: string, default: "adversarial_patch.tar.gz" }
      adv_patch_dir: { type: string, default: "adv_patches" }
      imagenet_preprocessing: { type: string, default: "false"}
      patch_deployment_method: {type: string, default: "augment"}
      patch_application_rate: {type: string, default: 1.0}
      patch_scale: {type: float, default: 0.4}
      batch_size: {type: float, default: 32}
      rotation_max: {type: float, default: 22.5}
      scale_min: {type: float, default: 0.1}
      scale_max: {type: float, default: 1.0}
      seed: {type: float, default: -1}
    command: >
      python deploy_patch.py
      --run-id {run_id}
      --data-dir {data_dir}
      --patch-deployment-method {patch_deployment_method}
      --patch-application-rate {patch_application_rate}
      --patch-scale {patch_scale}
      --batch-size {batch_size}
      --rotation-max {rotation_max}
      --scale-max {scale_max}
      --scale-min {scale_min}
      --model-name {model_name}
      --model-version {model_version}
      --image-size {image_size}
      --adv-tar-name {adv_tar_name}
      --adv-data-dir {adv_data_dir}
      --adv-patch-tar-name {adv_patch_tar_name}
      --adv-patch-dir {adv_patch_dir}
      --imagenet-preprocessing {imagenet_preprocessing}
      --seed {seed}

  spatial_smoothing:
    parameters:
      image_size: { type: string, default: "28,28,1" }
      def_tar_name: { type: string, default: "spatial_smoothing_dataset.tar.gz" }
      def_data_dir: { type: string, default: "adv_testing" }
      batch_size: { type: float, default: 32 }
      spatial_smoothing_window_size: {type: int, default: 3}
      spatial_smoothing_apply_fit: {type: string, default: "false"}
      spatial_smoothing_apply_predict: {type: string, default: "true"}
      dataset_run_id: {type: string, default: "none"}
      dataset_tar_name: {type: string, default: "adversarial_patch_dataset.tar.gz"}
      dataset_name: {type: string, default: "adv_patch_dataset"}
      seed: { type: float, default: -1 }
    command: >
      python spatial_smoothing.py
      --image-size {image_size}
      --def-tar-name {def_tar_name}
      --def-data-dir {def_data_dir}
      --batch-size {batch_size}
      --spatial-smoothing-window-size {spatial_smoothing_window_size}
      --spatial-smoothing-apply-fit {spatial_smoothing_apply_fit}
      --spatial-smoothing-apply-predict {spatial_smoothing_apply_predict}
      --dataset-run-id {dataset_run_id}
      --dataset-tar-name {dataset_tar_name}
      --dataset-name {dataset_name}
      --seed {seed}

  jpeg_compression:
    parameters:
      image_size: { type: string, default: "28,28,1" }
      def_tar_name: { type: string, default: "jpeg_compression_dataset.tar.gz" }
      def_data_dir: { type: string, default: "adv_testing" }
      batch_size: { type: float, default: 32 }
      jpeg_compression_channels_first: {type: string, default: "false"}
      jpeg_compression_quality: {type: int, default: 50}
      jpeg_compression_apply_fit: {type: string, default: "false"}
      jpeg_compression_apply_predict: {type: string, default: "true"}
      dataset_run_id: {type: string, default: "none"}
      dataset_tar_name: {type: string, default: "adversarial_patch_dataset.tar.gz"}
      dataset_name: {type: string, default: "adv_patch_dataset"}
      seed: { type: float, default: -1 }
    command: >
      python jpeg_compression.py
      --image-size {image_size}
      --def-tar-name {def_tar_name}
      --def-data-dir {def_data_dir}
      --batch-size {batch_size}
      --jpeg-compression-channels-first {jpeg_compression_channels_first}
      --jpeg-compression-quality {jpeg_compression_quality}
      --jpeg-compression-apply-fit {jpeg_compression_apply_fit}
      --jpeg-compression-apply-predict {jpeg_compression_apply_predict}
      --dataset-run-id {dataset_run_id}
      --dataset-tar-name {dataset_tar_name}
      --dataset-name {dataset_name}
      --seed {seed}

  gaussian_augmentation:
    parameters:
      image_size: { type: string, default: "28,28,1" }
      def_tar_name: { type: string, default: "gaussian_augmentation_dataset.tar.gz" }
      def_data_dir: { type: string, default: "adv_testing" }
      batch_size: { type: float, default: 32 }
      gaussian_augmentation_perform_data_augmentation: {type: string, default: "false"}
      gaussian_augmentation_ratio: {type: float, default: 1}
      gaussian_augmentation_sigma: {type: float, default: 1}
      gaussian_augmentation_apply_fit: {type: string, default: "false"}
      gaussian_augmentation_apply_predict: {type: string, default: "true"}
      dataset_run_id: {type: string, default: "none"}
      dataset_tar_name: {type: string, default: "adversarial_patch_dataset.tar.gz"}
      dataset_name: {type: string, default: "adv_patch_dataset"}
      seed: { type: float, default: -1 }
    command: >
      python gaussian_augmentation.py
      --image-size {image_size}
      --def-tar-name {def_tar_name}
      --def-data-dir {def_data_dir}
      --batch-size {batch_size}
      --gaussian-augmentation-perform-data-augmentation {gaussian_augmentation_perform_data_augmentation}
      --gaussian-augmentation-ratio {gaussian_augmentation_ratio}
      --gaussian-augmentation-sigma {gaussian_augmentation_sigma}
      --gaussian-augmentation-apply-fit {gaussian_augmentation_apply_fit}
      --gaussian-augmentation-apply-predict {gaussian_augmentation_apply_predict}
      --dataset-run-id {dataset_run_id}
      --dataset-tar-name {dataset_tar_name}
      --dataset-name {dataset_name}
      --seed {seed}


  infer:
    parameters:
      run_id: { type: string }
      image_size: { type: string, default: "28,28,1" }
      model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      model_version: { type: string, default: "1" }
      batch_size: { type: float, default: 32 }
      adv_tar_name: { type: string, default: "adversarial_patch_dataset.tar.gz" }
      adv_data_dir: { type: string, default: "adv_patch_dataset" }
      imagenet_preprocessing: { type: string, default: "false"}
      seed: { type: float, default: -1 }
    command: >
      python infer.py
      --run-id {run_id}
      --image-size {image_size}
      --model-name {model_name}
      --model-version {model_version}
      --batch-size {batch_size}
      --adv-tar-name {adv_tar_name}
      --adv-data-dir {adv_data_dir}
      --imagenet-preprocessing {imagenet_preprocessing}
      --seed {seed}

  train:
    parameters:
      data_dir_testing: { type: path, default: "/dioptra/data/Mnist/testing" }
      data_dir_training: { type: path, default: "/dioptra/data/Mnist/training" }
      image_size: { type: string, default: "28,28,1" }
      model_architecture: { type: string, default: "le_net" }
      epochs: { type: float, default: 30 }
      batch_size: { type: float, default: 32 }
      register_model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      learning_rate: { type: float, default: 0.001 }
      optimizer: { type: string, default: "Adam" }
      validation_split: { type: float, default: 0.2 }
      seed: { type: float, default: -1 }
    command: >
      python train.py
      --data-dir-testing {data_dir_testing}
      --data-dir-training {data_dir_training}
      --image-size {image_size}
      --model-architecture {model_architecture}
      --epochs {epochs}
      --batch-size {batch_size}
      --register-model-name {register_model_name}
      --learning-rate {learning_rate}
      --optimizer {optimizer}
      --validation-split {validation_split}
      --seed {seed}

  train_on_Mnist_patched:
    parameters:
      data_dir_testing: { type: path, default: "/dioptra/data/Mnist/testing" }
      image_size: { type: string, default: "28,28,1" }
      model_architecture: { type: string, default: "le_net" }
      epochs: { type: float, default: 30 }
      batch_size: { type: float, default: 32 }
      register_model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      learning_rate: { type: float, default: 0.001 }
      optimizer: { type: string, default: "Adam" }
      validation_split: { type: float, default: 0.2 }
      dataset_run_id_testing: {type: string, default: ""}
      dataset_run_id_training: {type: string, default: ""}
      adv_tar_name: { type: string, default: "adversarial_patch_dataset.tar.gz" }
      adv_data_dir: { type: string, default: "adv_patch_dataset" }
      seed: { type: float, default: -1 }
    command: >
      python train_on_Mnist_patched.py
      --data-dir-testing {data_dir_testing}
      --image-size {image_size}
      --model-architecture {model_architecture}
      --epochs {epochs}
      --batch-size {batch_size}
      --register-model-name {register_model_name}
      --learning-rate {learning_rate}
      --optimizer {optimizer}
      --validation-split {validation_split}
      --dataset-run-id-testing {dataset_run_id_testing}
      --dataset-run-id-training {dataset_run_id_training}
      --adv-tar-name {adv_tar_name}
      --adv-data-dir {adv_data_dir}
      --seed {seed}

  train_on_Fruits360_patched:
    parameters:
      data_dir_testing: { type: path, default: "/dioptra/data/Mnist/testing" }
      image_size: { type: string, default: "28,28,1" }
      model_architecture: { type: string, default: "le_net" }
      epochs: { type: float, default: 30 }
      batch_size: { type: float, default: 32 }
      register_model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      learning_rate: { type: float, default: 0.001 }
      optimizer: { type: string, default: "Adam" }
      validation_split: { type: float, default: 0.2 }
      dataset_run_id_testing: {type: string, default: ""}
      dataset_run_id_training: {type: string, default: ""}
      adv_tar_name: { type: string, default: "adversarial_patch_dataset.tar.gz" }
      adv_data_dir: { type: string, default: "adv_patch_dataset" }
      seed: { type: float, default: -1 }
    command: >
      python train_on_Fruits360_patched.py
      --data-dir-testing {data_dir_testing}
      --image-size {image_size}
      --model-architecture {model_architecture}
      --epochs {epochs}
      --batch-size {batch_size}
      --register-model-name {register_model_name}
      --learning-rate {learning_rate}
      --optimizer {optimizer}
      --validation-split {validation_split}
      --dataset-run-id-testing {dataset_run_id_testing}
      --dataset-run-id-training {dataset_run_id_training}
      --adv-tar-name {adv_tar_name}
      --adv-data-dir {adv_data_dir}
      --seed {seed}

  init_model:
    parameters:
      data_dir: { type: path, default: "/dioptra/data/ImageNet-Kaggle-2017/images/ILSVRC/Data/CLS-LOC/val-sorted-1000" }
      image_size: { type: string, default: "28,28,1" }
      model_architecture: { type: string, default: "resnet50" }
      batch_size: { type: float, default: 32 }
      register_model_name: { type: string, default: "imagenet_adversarial_patches_pretrained_resnet50" }
      learning_rate: { type: float, default: 0.001 }
      optimizer: { type: string, default: "Adam" }
      imagenet_preprocessing: { type: string, default: "false"}
      seed: { type: float, default: -1 }
    command: >
      python init_model.py
      --data-dir {data_dir}
      --image-size {image_size}
      --model-architecture {model_architecture}
      --batch-size {batch_size}
      --register-model-name {register_model_name}
      --learning-rate {learning_rate}
      --optimizer {optimizer}
      --imagenet-preprocessing {imagenet_preprocessing}
      --seed {seed}
